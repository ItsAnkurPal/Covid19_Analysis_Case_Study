# -*- coding: utf-8 -*-
"""ChaiCodeDSPractiseAnkur

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xecTI-2n0p4JISwHpj4myUPsECUV1pwi

**Question 1: Data Loading**
"""

# Importing the Required Libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""*Q1.1: How do you load the COVID-19 datasets for confirmed cases, deaths, and recoveries into Python using Pandas?*"""

#Loading the Files
confirmed_df = pd.read_csv('/content/drive/MyDrive/DataSets/covid_19_confirmed.csv',)
deaths_df = pd.read_csv('/content/drive/MyDrive/DataSets/covid_19_deaths.csv',header=1)
recovered_df = pd.read_csv('/content/drive/MyDrive/DataSets/covid_19_recovered.csv',header=1)

print(confirmed_df.head()) #Testing

print(recovered_df.head()) #Testing

print(deaths_df.head()) #Testing

"""**Question 2: Data Exploration**

*Q2.1: After loading the datasets, what is the structure of each dataset in terms of rows, columns, and data types?*
"""

confirmed_df.shape #In confirmed Cases dataset there are 276 rows and 498 columns

confirmed_df.dtypes #Need to change dtype of all dates will do this later

deaths_df.shape #In Deaths Cases dataset there are 276 rows and 498 columns

deaths_df.dtypes #Need to change dtype of all dates will do this later

recovered_df.shape #In Recovered Cases dataset there are 261 rows and 498 columns

recovered_df.dtypes #Need to change dtype of all dates will do this later

"""*Q2.2: Generate plots of confirmed cases over time for the top countries.*"""

# Group by country and get latest values
countries = confirmed_df.groupby('Country/Region').sum(numeric_only=True)
top_countries = countries.iloc[:, -1].sort_values(ascending=False).head(5)

# Plotting line chart
plt.figure(figsize=(10,5))
plt.plot(top_countries.index, top_countries.values, color='red', linewidth=1.5)
plt.title("Confirmed cases for top countries", fontsize=16)
plt.xlabel('Top Countries', fontsize=14)
plt.ylabel('Confirmed Cases', fontsize=14)
plt.xticks(rotation=45)
plt.grid(True)

plt.show()

"""*Q2.3: Generate plots of confirmed cases over time for China.*"""

# Filter data for China
china_df = confirmed_df[confirmed_df['Country/Region'] == 'China']

# Drop unnecessary columns and sum over provinces/states
china_timeseries = china_df.drop(columns=["Province/State", "Country/Region", "Lat", "Long"]).sum()

# Convert index to datetime for plotting
china_timeseries.index = pd.to_datetime(china_timeseries.index)

# Plot
plt.figure(figsize=(10, 5))
plt.plot(china_timeseries.index, china_timeseries.values, label="Confirmed Cases in China", color='red')
plt.xlabel("Date")
plt.ylabel("Confirmed Cases")
plt.title("COVID-19 Confirmed Cases Over Time in China")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Question 3: Handling Missing Data**

*Q3.1: Identify these missing values and replace them using a suitable imputation method, such as forward filling, for time-series data.*
"""

confirmed_df.isnull().sum() #In Lat and Long Column there are 2 Null Values each

confirmed_df['Lat'].fillna(method='ffill', inplace=True) #Imputing the null values using ffill
confirmed_df['Long'].fillna(method='ffill', inplace=True)
confirmed_df.isnull().sum()

deaths_df.isnull().sum()#In Lat and Long Column there are 2 Null Values each

deaths_df['Lat'].fillna(method='ffill', inplace=True)
deaths_df['Long'].fillna(method='ffill', inplace=True) #Imputing the null values using ffill
deaths_df.isnull().sum()

recovered_df.isnull().sum()#In Lat and Long Column there are 1 Null Values each

recovered_df['Lat'].fillna(method='ffill', inplace=True)
recovered_df['Long'].fillna(method='ffill', inplace=True)#Imputing the null values using ffill
recovered_df.isnull().sum()

"""**Question 4: Data Cleaning and Preparation**

*Q4.1: Replace blank values in the province column with “All Provinces.”*
"""

confirmed_df['Province/State'].fillna('All Provinces', inplace=True) #Replacing
deaths_df['Province/State'].fillna('All Provinces', inplace=True) #Replacing
recovered_df['Province/State'].fillna('All Provinces', inplace=True) #Replacing

"""**Question 5: Independent Dataset Analysis**

*Q5.1: Analyze the peak number of daily new cases in Germany, France, and Italy. Which country experienced the highest single-day surge, and when did it occur?*
"""

# Identifying the ddate dolumns from the confirmed dataset
date_cols = confirmed_df.columns[4:]

# Countries list
countries = ['Germany', 'France', 'Italy']

# Filter data for selected countries
subset = confirmed_df[confirmed_df['Country/Region'].isin(countries)]

# Sum cumulative cases per country (across provinces)
cum_cases = subset.groupby('Country/Region')[date_cols].sum()

# Calculate daily new cases by differencing cumulative sums
daily_new = cum_cases.diff(axis=1).fillna(0).astype(int)

# Reset index and melt to long format for easier handling
daily_new_long = daily_new.reset_index().melt(
    id_vars='Country/Region',
    value_vars=date_cols,
    var_name='Date',
    value_name='Daily New Cases'
)

# Convert Date column to datetime (important if it's int64)
daily_new_long['Date'] = pd.to_datetime(daily_new_long['Date'].astype(str), errors='coerce')

# Find peak daily cases for each country
peak = daily_new_long.loc[daily_new_long.groupby('Country/Region')['Daily New Cases'].idxmax()]

# Find overall highest single-day surge
max_peak = peak.loc[peak['Daily New Cases'].idxmax()]

# Peak daily new cases per country as a clean DataFrame
print("Peak daily new cases per country:\n")
print(peak[['Country/Region', 'Date', 'Daily New Cases']].to_string(index=False))

# Highest single-day surge overall in a formatted string
print("\nHighest single-day surge overall:")
print(f"Country       : {max_peak['Country/Region']}")
print(f"Date          : {max_peak['Date'].strftime('%Y-%m-%d')}")
print(f"New Cases     : {max_peak['Daily New Cases']}")

"""*Q5.2: Compare the recovery rates (recoveries/confirmed cases) between Canada and Australia as of December 31, 2020. Which country showed better management of the pandemic according to this metric?*"""

#Filter both datasets for Canada and Australia
countries = ['Canada', 'Australia']
confirmed_filtered = confirmed_df[confirmed_df['Country/Region'].isin(countries)]
recovered_filtered = recovered_df[recovered_df['Country/Region'].isin(countries)]

#Group by Country/Region and sum across provinces
confirmed_latest = confirmed_filtered.groupby('Country/Region').sum(numeric_only=True)
recovered_latest = recovered_filtered.groupby('Country/Region').sum(numeric_only=True)

#Extract values for 2020-12-31
date_col = '12/31/20'
confirmed_1231 = confirmed_latest[date_col]
recovered_1231 = recovered_latest[date_col]

#Compute recovery rate
recovery_rate = (recovered_1231 / confirmed_1231).fillna(0) * 100  # in percentage

#Display results
print("Recovery rates as of December 31, 2020:\n")
for country in countries:
    print(f"{country}: {recovery_rate[country]:.2f}%")

# Step 6: Determine better performing country
best_country = recovery_rate.idxmax()
print(f"\n{best_country} showed better pandemic management by recovery rate.")

"""*Q5.3: What is the distribution of death rates (deaths/confirmed cases) among provinces in Canada? Identify the province with the highest and lowest death rate as of the latest data point.*"""

# Filter data for Canada
canada_confirmed = confirmed_df[confirmed_df['Country/Region'] == 'Canada']
canada_deaths = deaths_df[deaths_df['Country/Region'] == 'Canada']

# Get the latest date column
latest_date = confirmed_df.columns[-1]

# Sum confirmed cases and deaths per province on the latest date
canada_confirmed_latest = canada_confirmed.groupby('Province/State')[latest_date].sum()
canada_deaths_latest = canada_deaths.groupby('Province/State')[latest_date].sum()

# Replace 0 confirmed cases with NaN to avoid division by zero
safe_confirmed = canada_confirmed_latest.replace(0, pd.NA)

# Compute death rate
canada_death_rate = (canada_deaths_latest / safe_confirmed) * 100
canada_death_rate = canada_death_rate.fillna(0)

# Sort the death rates
canada_death_rate_sorted = canada_death_rate.sort_values(ascending=False)

# Print distribution
print("Distribution of death rates among provinces in Canada (latest data):\n")
print(canada_death_rate_sorted.to_string())

# Highest death rate
highest_death_rate_province = canada_death_rate_sorted.idxmax()
highest_death_rate_value = canada_death_rate_sorted.max()

# Lowest death rate (excluding 0 confirmed cases)
canada_death_rate_filtered = canada_death_rate[safe_confirmed.notna()]
lowest_death_rate_province = canada_death_rate_filtered.idxmin()
lowest_death_rate_value = canada_death_rate_filtered.min()

print(f"\nProvince with the highest death rate: {highest_death_rate_province} ({highest_death_rate_value:.2f}%)")
print(f"Province with the lowest death rate: {lowest_death_rate_province} ({lowest_death_rate_value:.2f}%)")

"""**Question 6: Data Transformation**

*Q6.1: Transform the 'deaths' dataset from wide format (where each column represents a date) to long format, where each row represents a single date, ensuring that the date column is in datetime format. How would this transformation be executed?*
"""

"""----------------------Deaths dataset---------------------"""
# Identifying the ddate dolumns from the confirmed dataset
date_cols = deaths_df.columns[4:]

#Unpivoting the deaths dataframe wide to long  format and storing the result in long_deaths
long_deaths = deaths_df.melt(
    id_vars=['Country/Region', 'Province/State'],
    value_vars=date_cols,
    var_name='Date',
    value_name='Deaths'
)
long_deaths['Date'] = pd.to_datetime(long_deaths['Date'], format='%m/%d/%y')
long_deaths

"""*Similar Operation on Confirmed dataset*"""

"""----------------------Confirmed dataset---------------------"""
date_cols = confirmed_df.columns[4:]
long_confirmed = confirmed_df.melt(
    id_vars=['Country/Region', 'Province/State'],
    value_vars=date_cols,
    var_name='Date',
    value_name='Confirmed'
)
long_confirmed['Date'] = pd.to_datetime(long_confirmed['Date'], format='%m/%d/%y')
long_confirmed

"""*Similar Operation on Recovered dataset*"""

"""----------------------Recovered dataset---------------------"""
date_cols = recovered_df.columns[4:]
long_recovered = recovered_df.melt(
    id_vars=['Country/Region', 'Province/State'],
    value_vars=date_cols,
    var_name='Date',
    value_name='Recovered'
)

long_recovered['Date'] = pd.to_datetime(long_recovered['Date'], format='%m/%d/%y')
long_recovered

"""*Q6.2: What is the total number of deaths reported per country up to the current date?*"""

# Fetch the current date
current_date=date_cols[-1]

# Group by Country and adding the death for each country
deaths_per_country = (deaths_df.groupby('Country/Region')[current_date].sum().sort_values(ascending=False))
print(f"Total deaths per country up to the {current_date}")
print(deaths_per_country)

"""*Q6.3: What are the top 5 countries with the highest average daily deaths?*"""

# Feth all countries from deaths df and summing deaths for each country
country_with_deaths = deaths_df.groupby('Country/Region')[date_cols].sum()
first_date = date_cols[0]
daily_deaths = country_with_deaths.diff(axis=1)
daily_deaths[first_date] = country_with_deaths[first_date]
avg_daily_deaths = daily_deaths.mean(axis=1)
top5_avg_deaths = avg_daily_deaths.sort_values(ascending=False).head(5)
print(f"Top 5 countries with the highest average daily deaths\n{top5_avg_deaths}")

"""*Q6.4: How have the total deaths evolved over time in the United States?*"""

# Filter rows for United States
us_data = deaths_df[deaths_df['Country/Region'] == 'US']

# Sum across provinces/states for each date (columns)
us_total_deaths = us_data[date_cols].sum()

# Convert date columns to datetime (if not already)
us_total_deaths.index = pd.to_datetime(us_total_deaths.index, format='%m/%d/%y')

# Plot the total deaths over time
plt.figure(figsize=(10,5))
plt.plot(us_total_deaths.index, us_total_deaths.values, color='red',linewidth=1.5)
plt.title('Total COVID-19 Deaths Over Time in the United States')
plt.xlabel('Date')
plt.ylabel('Total Deaths')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Question 7: Data Merging**

*Q7.1: How would you merge the transformed datasets of confirmed cases, deaths, and recoveries on the 'Country/Region' and 'Date' columns to create a comprehensive view of the pandemic's impact?*
"""

# First merge confirmed and deaths dataframe on common columns
merge_df_confirmed_deaths = pd.merge(long_confirmed, long_deaths, on=['Country/Region', 'Province/State', 'Date'], how='outer')
merge_df_confirmed_deaths

# Now merge recovered with the result of merged df of confirmed and deaths
merged_df=merge_df_confirmed_deaths.merge(long_recovered, on=['Country/Region', 'Province/State', 'Date'], how='outer')
merged_df

"""*Q7.2:Analyze the monthly sum of confirmed cases, deaths, and recoveries for countries to understand the progression of the pandemic.[From the merged dataset]*"""

#Group by Country and country wise progression
monthly_progress=merged_df.groupby(['Country/Region', pd.Grouper(key='Date', freq='M')])[['Confirmed', 'Deaths', 'Recovered']].sum()
monthly_progress

"""*Q7.3: Redo the analysis in Question 7.2 for the United States, Italy, and Brazil.*"""

#Group by Country and country wise progression for nited States, Italy, and Brazil.
monthly_progress[monthly_progress.index.get_level_values('Country/Region').isin(['United States', 'Italy', 'Brazil'])]

"""**Question 8: Combined Data Analysis**

*Q8.1: For the combined dataset, identify the three countries with the highest average death rates (deaths/confirmed cases) throughout 2020. What might this indicate about the pandemic's impact in these countries?*
"""

merged_df_2020 = merged_df[merged_df['Date'].dt.year == 2020].copy()

# Calculate the death rate for each entry
merged_df_2020['Death Rate'] = (merged_df_2020['Deaths'] / merged_df_2020['Confirmed']).fillna(0).replace([float('inf'), -float('inf')], 0)

# Group by country and calculate the average death rate
average_death_rate_2020 = merged_df_2020.groupby('Country/Region')['Death Rate'].mean()

# Get the top 3 countries with the highest average death rates
top3_countries_highest_death_rate = average_death_rate_2020.sort_values(ascending=False).head(3)

print("Top 3 countries with the highest average death rates in 2020:")
top3_countries_highest_death_rate

"""*Q8.2: Using the merged dataset, compare the total number of recoveries to the total number of deaths in South Africa. What can this tell us about the outcomes of COVID-19 cases in the country?*"""

# Filter the merged dataset for South Africa
south_africa_data = merged_df[merged_df['Country/Region'] == 'South Africa']

# Calculate the total number of recoveries and deaths
total_recoveries_sa = south_africa_data['Recovered'].sum()
total_deaths_sa = south_africa_data['Deaths'].sum()

print(f"Total Recoveries in South Africa: {total_recoveries_sa}")
print(f"Total Deaths in South Africa: {total_deaths_sa}")

if total_recoveries_sa > total_deaths_sa:
  print("\nIn South Africa, the total number of recoveries is significantly higher than the total number of deaths.")
elif total_deaths_sa > total_recoveries_sa:
  print("\nIn South Africa, the total number of deaths is higher than the total number of recoveries.")
else:
  print("\nIn South Africa, the total number of recoveries is approximately equal to the total number of deaths.")

"""*Q8.3: Analyze the ratio of recoveries to confirmed cases for the United States monthly from March 2020 to May 2021. Which month experienced the highest recovery ratio, and what could be the potential reasons?*"""

# Filter data for the United States and the specified time period
us_data= merged_df[
    (merged_df['Country/Region'] == 'US') &
    (merged_df['Date'] >= '2020-03-01') &
    (merged_df['Date'] <= '2021-05-31')
].copy()

# Group by month and calculate sum of confirmed cases and recoveries
us_data = us_data.groupby(pd.Grouper(key='Date', freq='M'))[['Confirmed', 'Recovered']].sum()

# Calculate the recovery ratio
us_data['Recovery Ratio'] = (us_data['Recovered'] / us_data['Confirmed']).fillna(0).replace([float('inf'), -float('inf')], 0)

# Find the month with the highest recovery ratio
highest_recovery_month = us_data['Recovery Ratio'].idxmax()
highest_recovery_ratio_value = us_data['Recovery Ratio'].max()

print("Monthly Recovery Ratio for the United States (March 2020 - May 2021):")
print(us_data[['Recovery Ratio']].to_string())

print(f"\nMonth with the highest recovery ratio: {highest_recovery_month.strftime('%Y-%m')}")
print(f"Highest recovery ratio: {highest_recovery_ratio_value:.4f}")

